import requests
import websockets
import asyncio
from datetime import datetime
import time
import re
import uuid
import argparse
from pydub import AudioSegment
from sub_thread import *
import queue

msg_que = queue.Queue(30)

class TTSClss():
    def __init__(self) -> None:
        pass

    # Fix the time to match Americanisms
    def hr_cr(self, hr):
        corrected = (hr - 1) % 24
        return str(corrected)

    # Add zeros in the right places i.e 22:1:5 -> 22:01:05
    def fr(self, input_string):
        corr = ''
        i = 2 - len(input_string)
        while (i > 0):
            corr += '0'
            i -= 1
        return corr + input_string
    
    # Generate X-Timestamp all correctly formatted
    def getXTime(self):
        now = datetime.now()
        return self.fr(str(now.year)) + '-' + self.fr(str(now.month)) + '-' + self.fr(str(now.day)) + 'T' + self.fr(self.hr_cr(int(now.hour))) + ':' + self.fr(str(now.minute)) + ':' + self.fr(str(now.second)) + '.' + str(now.microsecond)[:3] + 'Z'


    async def _subThreadProcess(self, *args, **kwargs):
        outputPath = kwargs['outputPath']
        ws_fd = kwargs['ws_fd']
        msg_content = kwargs['msg_content']

        start = self.getXTime()
        print("\nauth time end:" + start +"\n")
        
        spd='0'
        ptc='0'
        voice='zh-CN-XiaoxiaoNeural'
        payload_3 = '<speak xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="http://www.w3.org/2001/mstts" xmlns:emo="http://www.w3.org/2009/10/emotionml" version="1.0" xml:lang="en-US"><voice name="' + voice + '"><prosody rate="'+spd+'%" pitch="'+ptc+'%">'+ msg_content +'</prosody></voice></speak>'
        #print(payload_3)
        #payload_3 = SSML_text
        #print(payload_3)
        message_3 = 'Path: ssml\r\nX-RequestId: ' + self.req_id + '\r\nX-Timestamp: ' + \
            self.getXTime() + '\r\nContent-Type: application/ssml+xml\r\n\r\n' + payload_3
        await self.websocket.send(message_3)
        start = self.getXTime()
        print(start)

        # Checks for close connection message
        end_resp_pat = re.compile('Path:turn.end')
        audio_stream = b''
        while(True):
            print('--------------recv--------------')
            response = await self.websocket.recv()
            end = self.getXTime()
            #print(end - start)
            #print('receiving...')
            # Make sure the message isn't telling us to stop
            if (re.search(end_resp_pat, str(response)) == None):
                # Check if our response is text data or the audio bytes
                if type(response) == type(bytes()):
                    # Extract binary data
                    try:
                        start_ind = str(response).find('Path:audio')
                        #audio_string += str(response)[start_ind+14:-1]
                        tmp = response[start_ind-2:]
                        audio_stream += tmp
                        #print(audio_stream, type(audio_stream))
                        #await ws_fd.send(tmp)
                        #print(len(tmp))
                    except:
                        pass
            else:
                break
        start = self.getXTime()
        print("\n recv time end:" + start +"\n")
        with open(f'{outputPath}.mp3', 'wb') as audio_out:
            audio_out.write(audio_stream)
        sound = AudioSegment.from_mp3(f'{outputPath}.mp3')
        sound = sound.set_channels(2)
        sound.export(f'{outputPath}.wav', format="wav")
        url= 'http://192.168.73.249:8000/' + f'{outputPath}.wav'
        with open(f'{outputPath}.wav', 'rb') as f:
            res = f.read(44)
            while True:
                res = f.read(1024)
                if len(res) == 0:
                    break
                await ws_fd.send(res)
        await ws_fd.send(b'\x03\xe8')


    async def transferMsTTSDataRun(self):
        '''
        endpoint1 = "https://azure.microsoft.com/en-gb/services/cognitive-services/text-to-speech/"
        r = requests.get(endpoint1)
        main_web_content = r.text
        # They hid the Auth key assignment for the websocket in the main body of the webpage....
        token_expr = re.compile('token: \"(.*?)\"', re.DOTALL)
        Auth_Token = re.findall(token_expr, main_web_content)[0]
        # self.req_id = str('%032x' % random.getrandbits(128)).upper()
        # self.req_id is generated by uuid.
        self.req_id = uuid.uuid4().hex.upper()
        print(self.req_id)
        endpoint2 = "wss://eastus.tts.speech.microsoft.com/cognitiveservices/websocket/v1?Authorization=" + \
            Auth_Token + "&X-ConnectionId=" + self.req_id
        async with websockets.connect(endpoint2) as self.websocket:
            payload_1 = '{"context":{"system":{"name":"SpeechSDK","version":"1.12.1-rc.1","build":"JavaScript","lang":"JavaScript","os":{"platform":"Browser/Linux x86_64","name":"Mozilla/5.0 (X11; Linux x86_64; rv:78.0) Gecko/20100101 Firefox/78.0","version":"5.0 (X11)"}}}}'
            message_1 = 'Path : speech.config\r\nX-RequestId: ' + self.req_id + '\r\nX-Timestamp: ' + \
                self.getXTime() + '\r\nContent-Type: application/json\r\n\r\n' + payload_1
            await self.websocket.send(message_1)

            payload_2 = '{"synthesis":{"audio":{"metadataOptions":{"sentenceBoundaryEnabled":false,"wordBoundaryEnabled":false},"outputFormat":"audio-16khz-32kbitrate-mono-mp3"}}}'
            message_2 = 'Path : synthesis.context\r\nX-RequestId: ' + self.req_id + '\r\nX-Timestamp: ' + \
                self.getXTime() + '\r\nContent-Type: application/json\r\n\r\n' + payload_2
            await self.websocket.send(message_2)


            # run forver
            while True:
                print('before msg get')
                ttsMsg = msg_que.get()
                print('ttsMsg', ttsMsg)
                print('msg get')
                outputPath = ttsMsg['outputPath']
                ws_fd = ttsMsg['ws_fd']
                msg_content = ttsMsg['msg_content']
                # thread_run(self._subThreadProcess, outputPath=outputPath, ws_fd=ws_fd, msg_content=msg_content)
                await self._subThreadProcess(outputPath=outputPath, ws_fd=ws_fd, msg_content=msg_content)

        '''
            
        while True:
            print('before msg get')
            ttsMsg = msg_que.get()
            print('ttsMsg', ttsMsg)

            endpoint1 = "https://azure.microsoft.com/en-gb/services/cognitive-services/text-to-speech/"
            r = requests.get(endpoint1)
            main_web_content = r.text
            # They hid the Auth key assignment for the websocket in the main body of the webpage....
            token_expr = re.compile('token: \"(.*?)\"', re.DOTALL)
            Auth_Token = re.findall(token_expr, main_web_content)[0]
            # self.req_id = str('%032x' % random.getrandbits(128)).upper()
            # self.req_id is generated by uuid.
            self.req_id = uuid.uuid4().hex.upper()
            print(self.req_id)
            endpoint2 = "wss://eastus.tts.speech.microsoft.com/cognitiveservices/websocket/v1?Authorization=" + \
                Auth_Token + "&X-ConnectionId=" + self.req_id
            async with websockets.connect(endpoint2) as self.websocket:
                payload_1 = '{"context":{"system":{"name":"SpeechSDK","version":"1.12.1-rc.1","build":"JavaScript","lang":"JavaScript","os":{"platform":"Browser/Linux x86_64","name":"Mozilla/5.0 (X11; Linux x86_64; rv:78.0) Gecko/20100101 Firefox/78.0","version":"5.0 (X11)"}}}}'
                message_1 = 'Path : speech.config\r\nX-RequestId: ' + self.req_id + '\r\nX-Timestamp: ' + \
                    self.getXTime() + '\r\nContent-Type: application/json\r\n\r\n' + payload_1
                await self.websocket.send(message_1)

                payload_2 = '{"synthesis":{"audio":{"metadataOptions":{"sentenceBoundaryEnabled":false,"wordBoundaryEnabled":false},"outputFormat":"audio-16khz-32kbitrate-mono-mp3"}}}'
                message_2 = 'Path : synthesis.context\r\nX-RequestId: ' + self.req_id + '\r\nX-Timestamp: ' + \
                    self.getXTime() + '\r\nContent-Type: application/json\r\n\r\n' + payload_2
                await self.websocket.send(message_2)

                outputPath = ttsMsg['outputPath']
                ws_fd = ttsMsg['ws_fd']
                msg_content = ttsMsg['msg_content']
                # thread_run(self._subThreadProcess, outputPath=outputPath, ws_fd=ws_fd, msg_content=msg_content)
                await self._subThreadProcess(outputPath=outputPath, ws_fd=ws_fd, msg_content=msg_content)
                

async def gate(ws):
    '''
    while True:
        msg_content = await ws.recv()
    '''
    async for message in ws:
        if message == '':
            message = '内容不能为空'
        msg_content = message
        print(f'recv: {message}')
        outputPath = 'output_'+ str(int(time.time()*1000))

        post = {'msg_content':msg_content, 'outputPath':outputPath, 'ws_fd':ws}
        msg_que.put(post)

        # await mainSeq(msg_content, output_path, ws)
        # await ws.send(b'\x03\xe8')

async def tts_server():
    async with websockets.serve(gate, "192.168.73.249", 8766, max_size = 10752000):
        await asyncio.Future()  # run forever

def convet_process():
    
    new_loop = asyncio.new_event_loop()
    asyncio.set_event_loop(new_loop)
    ttsProcess = TTSClss()

    asyncio.get_event_loop().run_until_complete(ttsProcess.transferMsTTSDataRun())

def tts_server_thread():
    new_loop = asyncio.new_event_loop()
    asyncio.set_event_loop(new_loop)
    ioloop = asyncio.get_event_loop()

    # tasks中也可以使用asyncio.ensure_future(gr1())..
    tasks = [ioloop.create_task(tts_server())]
    ioloop.run_until_complete(asyncio.wait(tasks))
    ioloop.close()


if __name__ == '__main__':
    
    thread_run(convet_process)
    thread_run(tts_server_thread)

    # asyncio.run(tts_server())

    while True:
        time.sleep(10)

outputPath